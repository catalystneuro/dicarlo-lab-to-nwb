{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amplifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# This has to be modified for experiment_path\n",
    "experiment_path = Path(\"/media/heberto/One Touch/DiCarlo-CN-data-share/exp_domain-transfer-2023/exp_domain-transfer-2023.sub_pico/raw_files/intanraw\")\n",
    "assert experiment_path.is_dir()\n",
    "session_folder =  experiment_path / \"pico_domain-transfer-2023_230215_161322\"\n",
    "#session_folder = experiment_path / \"pico_domain-transfer-2023_230214_140610\"  # This file has a timestamp problem\n",
    "assert session_folder.is_dir()\n",
    "\n",
    "file_path = session_folder / \"info.rhd\"\n",
    "assert file_path.is_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spikeinterface.extractors import IntanRecordingExtractor\n",
    "\n",
    "\n",
    "recording = IntanRecordingExtractor(\n",
    "    file_path=file_path,\n",
    "    stream_name=\"RHD2000 amplifier channel\",\n",
    "    all_annotations=True,\n",
    "    ignore_integrity_checks=True,\n",
    ")\n",
    "recording"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auxiliary input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_auxiliary_input = IntanRecordingExtractor(\n",
    "    file_path=file_path,\n",
    "    stream_name=\"RHD2000 auxiliary input channel\",\n",
    "    all_annotations=True,\n",
    "    ignore_integrity_checks=True,\n",
    ")\n",
    "\n",
    "recording_auxiliary_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADC input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_adc_input = IntanRecordingExtractor(\n",
    "    file_path=file_path,\n",
    "    stream_name=\"USB board ADC input channel\",\n",
    "    all_annotations=True,\n",
    "    ignore_integrity_checks=True,\n",
    ")\n",
    "\n",
    "recording_adc_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Digital channel \n",
    "Requires neo version from github https://github.com/NeuralEnsemble/python-neo/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_digital = IntanRecordingExtractor(\n",
    "    file_path=file_path,\n",
    "    stream_name=\"USB board digital input channel\",\n",
    "    all_annotations=True,\n",
    "    ignore_integrity_checks=True,\n",
    ")\n",
    "\n",
    "recording_digital"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artificial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spikeinterface.widgets as sw\n",
    "\n",
    "from spikeinterface.core.generate import generate_ground_truth_recording\n",
    "\n",
    "\n",
    "recording, sorting = generate_ground_truth_recording(num_channels=4, num_units=1, durations=[1], seed=0)\n",
    "\n",
    "\n",
    "w_ts = sw.plot_traces(recording, time_range=(0, 1))\n",
    "w_rs = sw.plot_rasters(sorting, time_range=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from dicarlo_lab_to_nwb.conversion.pipeline import di_carlo_peak_detection\n",
    "\n",
    "\n",
    "\n",
    "job_kwargs = dict(n_jobs=1, verbose=True, progress_bar=True, chunk_duration=1.0)\n",
    "noise_threshold = 3  # The number of standard deviations for peak detection\n",
    "\n",
    "spike_times_per_channel = di_carlo_peak_detection(recording=recording, noise_threshold=noise_threshold, job_kwargs=job_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting.get_unit_spike_train(0, return_times=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_times_per_channel[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import spikeinterface.widgets as sw\n",
    "\n",
    "from spikeinterface.extractors import IntanRecordingExtractor\n",
    "\n",
    "\n",
    "# This has to be modified for experiment_path\n",
    "experiment_path = Path(\n",
    "    \"/media/heberto/One Touch/DiCarlo-CN-data-share/exp_domain-transfer-2023/exp_domain-transfer-2023.sub_pico/raw_files/intanraw\"\n",
    ")\n",
    "assert experiment_path.is_dir()\n",
    "session_folder = experiment_path / \"pico_domain-transfer-2023_230215_161322\"\n",
    "# session_folder = experiment_path / \"pico_domain-transfer-2023_230214_140610\"  # This file has a timestamp problem\n",
    "assert session_folder.is_dir()\n",
    "\n",
    "file_path = session_folder / \"info.rhd\"\n",
    "assert file_path.is_file()\n",
    "\n",
    "\n",
    "recording = IntanRecordingExtractor(\n",
    "    file_path=file_path,\n",
    "    stream_name=\"RHD2000 amplifier channel\",\n",
    "    all_annotations=True,\n",
    "    ignore_integrity_checks=True,\n",
    ")\n",
    "\n",
    "# If you want to select only one channel\n",
    "channel_ids = recording.get_channel_ids()[0:1]\n",
    "recording = recording.select_channels(channel_ids=channel_ids)\n",
    "w_ts = sw.plot_traces(recording, time_range=(0, 1), return_scaled=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dicarlo_lab_to_nwb.conversion.pipeline import DiCarloBandPass, DiCarloNotch\n",
    "\n",
    "\n",
    "f_notch = 50  # Hz\n",
    "bandwidth = 10\n",
    "f_low = 300.0\n",
    "f_high = 6000.0\n",
    "\n",
    "vectorized = True \n",
    "notched_recording = DiCarloNotch(recording, f_notch=f_notch, bandwidth=bandwidth, vectorized=vectorized)\n",
    "preprocessed_recording = DiCarloBandPass(notched_recording, f_low=f_low, f_high=f_high, vectorized=vectorized)\n",
    "\n",
    "# For this instance each array 96 channels, 400 micrometes apart\n",
    "w_ts = sw.plot_traces(preprocessed_recording, time_range=(0, 1), return_scaled=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the peak detection on a short portion of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dicarlo_lab_to_nwb.conversion.pipeline import di_carlo_peak_detection\n",
    "\n",
    "noise_threshold = 3  # The number of standard deviations for peak detection\n",
    "\n",
    "start_frame = 0\n",
    "seconds_of_data = 1.0\n",
    "end_frame = int(preprocessed_recording.sampling_frequency * seconds_of_data)\n",
    "preprocessed_recording = preprocessed_recording.frame_slice(start_frame=start_frame, end_frame=end_frame)\n",
    "\n",
    "spike_times_per_channel = di_carlo_peak_detection(\n",
    "    recording=preprocessed_recording,\n",
    "    noise_threshold=noise_threshold,\n",
    ")\n",
    "\n",
    "spike_times_per_channel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Everything can be wrapped up in a couple of lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dicarlo_lab_to_nwb.conversion.pipeline import di_carlo_pipeline\n",
    "\n",
    "\n",
    "image_set_name = \"domain-transfer-2023\"\n",
    "subject = \"pico\"\n",
    "session_date = \"20230214\"\n",
    "session_time = \"140610\"\n",
    "\n",
    "# Parameters of the pipeline\n",
    "f_notch = 50  # Hz\n",
    "bandwidth = 10\n",
    "f_low = 300.0\n",
    "f_high = 6000.0\n",
    "noise_threshold = 3  # The number of standard deviations for peak detection\n",
    "\n",
    "\n",
    "data_folder = Path(\"/media/heberto/One Touch/DiCarlo-CN-data-share\")\n",
    "assert data_folder.is_dir(), f\"Data directory not found: {data_folder}\"\n",
    "\n",
    "experiment_folder = data_folder / f\"exp_{image_set_name}\"\n",
    "assert experiment_folder.is_dir(), f\"Experiment folder not found: {experiment_folder}\"\n",
    "\n",
    "subject_folder = experiment_folder / f\"exp_{image_set_name}.sub_{subject}\"\n",
    "assert subject_folder.is_dir(), f\"Subject folder not found: {subject_folder}\"\n",
    "\n",
    "raw_data_folder = subject_folder / \"raw_files\"\n",
    "assert raw_data_folder.is_dir(), f\"Raw files folder not found: {raw_data_folder}\"\n",
    "\n",
    "intan_session_folder = raw_data_folder / \"intanraw\" / f\"{subject}_{image_set_name}_{session_date[2:]}_{session_time}\"\n",
    "assert intan_session_folder.is_dir(), f\"Intan session folder not found: {intan_session_folder}\"\n",
    "\n",
    "intan_file_path = intan_session_folder / \"info.rhd\"\n",
    "\n",
    "\n",
    "stream_name = \"RHD2000 amplifier channel\"\n",
    "recording = IntanRecordingExtractor(\n",
    "    file_path=intan_file_path,\n",
    "    stream_name=stream_name,\n",
    "    ignore_integrity_checks=True,\n",
    "    all_annotations=True,\n",
    ")\n",
    "\n",
    "spike_times_per_channel_vectorized = di_carlo_pipeline(\n",
    "    recording=recording.frame_slice(start_frame=0, end_frame=1000), # Remove frame_slice to run the whole pipeline\n",
    "    f_notch=f_notch,\n",
    "    bandwidth=bandwidth,\n",
    "    f_low=f_low,\n",
    "    f_high=f_high,\n",
    "    noise_threshold=noise_threshold,\n",
    ")\n",
    "\n",
    "spike_times_per_channel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speed comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from spikeinterface.extractors import IntanRecordingExtractor\n",
    "from dicarlo_lab_to_nwb.conversion.pipeline import di_carlo_pipeline\n",
    "\n",
    "image_set_name = \"domain-transfer-2023\"\n",
    "subject = \"pico\"\n",
    "session_date = \"20230214\"\n",
    "session_time = \"140610\"\n",
    "\n",
    "# Parameters of the pipeline\n",
    "f_notch = 50  # Hz\n",
    "bandwidth = 10\n",
    "f_low = 300.0\n",
    "f_high = 6000.0\n",
    "noise_threshold = 3  # The number of standard deviations for peak detection\n",
    "\n",
    "data_folder = Path(\"/media/heberto/One Touch/DiCarlo-CN-data-share\")\n",
    "assert data_folder.is_dir(), f\"Data directory not found: {data_folder}\"\n",
    "\n",
    "experiment_folder = data_folder / f\"exp_{image_set_name}\"\n",
    "assert experiment_folder.is_dir(), f\"Experiment folder not found: {experiment_folder}\"\n",
    "\n",
    "subject_folder = experiment_folder / f\"exp_{image_set_name}.sub_{subject}\"\n",
    "assert subject_folder.is_dir(), f\"Subject folder not found: {subject_folder}\"\n",
    "\n",
    "raw_data_folder = subject_folder / \"raw_files\"\n",
    "assert raw_data_folder.is_dir(), f\"Raw files folder not found: {raw_data_folder}\"\n",
    "\n",
    "intan_session_folder = raw_data_folder / \"intanraw\" / f\"{subject}_{image_set_name}_{session_date[2:]}_{session_time}\"\n",
    "assert intan_session_folder.is_dir(), f\"Intan session folder not found: {intan_session_folder}\"\n",
    "\n",
    "intan_file_path = intan_session_folder / \"info.rhd\"\n",
    "\n",
    "\n",
    "stream_name = \"RHD2000 amplifier channel\"\n",
    "recording = IntanRecordingExtractor(\n",
    "    file_path=intan_file_path,\n",
    "    stream_name=stream_name,\n",
    "    ignore_integrity_checks=True,\n",
    "    all_annotations=True,\n",
    ")\n",
    "\n",
    "\n",
    "recording"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline vectorized vs non-vectorized\n",
    "We do the comparision with some seconds of data only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_frame = 0\n",
    "seconds_of_data = 16.0\n",
    "end_frame = int(recording.sampling_frequency * seconds_of_data)\n",
    "recording_short = recording.frame_slice(start_frame=start_frame, end_frame=end_frame)\n",
    "recording_to_use = recording_short\n",
    "\n",
    "vectorized = True\n",
    "job_kwargs = dict(n_jobs=1, progress_bar=True, verbose=True, chunk_duration=1.0)\n",
    "\n",
    "time_start = time.time()\n",
    "\n",
    "spike_times_per_channel_vectorized = di_carlo_pipeline(\n",
    "    recording=recording_to_use,\n",
    "    f_notch=f_notch,\n",
    "    bandwidth=bandwidth,\n",
    "    f_low=f_low,\n",
    "    f_high=f_high,\n",
    "    noise_threshold=noise_threshold,\n",
    "    vectorized=vectorized,\n",
    "    job_kwargs=job_kwargs,\n",
    ")\n",
    "\n",
    "time_stop = time.time()\n",
    "time_taken = time_stop - time_start\n",
    "print(f\"Time elapsed: {time_taken} seconds\")\n",
    "\n",
    "time_vectorized = time_taken\n",
    "\n",
    "\n",
    "vectorized = False\n",
    "time_start = time.time()\n",
    "\n",
    "spike_times_per_channel = di_carlo_pipeline(\n",
    "    recording=recording_to_use,\n",
    "    f_notch=f_notch,\n",
    "    bandwidth=bandwidth,\n",
    "    f_low=f_low,\n",
    "    f_high=f_high,\n",
    "    noise_threshold=noise_threshold,\n",
    "    vectorized=vectorized,\n",
    "    job_kwargs=job_kwargs,\n",
    ")\n",
    "\n",
    "time_stop = time.time()\n",
    "time_taken = time_stop - time_start\n",
    "print(f\"Time elapsed: {time_taken} seconds\")\n",
    "\n",
    "time_non_vectorized = time_taken\n",
    "\n",
    "speedup = time_non_vectorized/time_vectorized\n",
    "print(f\"Speedup: {speedup:.2f} (times faster)\" )\n",
    "\n",
    "# Test that the results are the same\n",
    "for channel_index, spike_times in spike_times_per_channel.items():\n",
    "    spike_times_vectorized = spike_times_per_channel_vectorized[channel_index]\n",
    "    assert np.allclose(spike_times, spike_times_vectorized), f\"Channel {channel_index} spike times do not match\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_to_use = recording_short\n",
    "vectorized = True\n",
    "time_start = time.time()\n",
    "job_kwargs = dict(n_jobs=-1, progress_bar=True, verbose=True, chunk_duration=1.0)\n",
    "\n",
    "spike_times_per_channel = di_carlo_pipeline(\n",
    "    recording=recording_to_use,\n",
    "    f_notch=f_notch,\n",
    "    bandwidth=bandwidth,\n",
    "    f_low=f_low,\n",
    "    f_high=f_high,\n",
    "    noise_threshold=noise_threshold,\n",
    "    vectorized=vectorized,\n",
    "    job_kwargs=job_kwargs,\n",
    ")\n",
    "\n",
    "time_stop = time.time()\n",
    "time_taken = time_stop - time_start\n",
    "print(f\"Time elapsed: {time_taken} seconds\")\n",
    "\n",
    "time_vectorized_multiprocessing  = time_taken\n",
    "\n",
    "speedup = time_non_vectorized/time_vectorized_multiprocessing\n",
    "print(f\"Speedup: {speedup:.2f} (times faster)\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full recording parallelize in multiple cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "recording_to_use = recording\n",
    "vectorized = True\n",
    "\n",
    "job_kwargs = dict(n_jobs=-1, progress_bar=True, verbose=True, chunk_duration=1.0)\n",
    "\n",
    "time_start = time.time()\n",
    "\n",
    "spike_times_per_channel = di_carlo_pipeline(\n",
    "    recording=recording_to_use,\n",
    "    f_notch=f_notch,\n",
    "    bandwidth=bandwidth,\n",
    "    f_low=f_low,\n",
    "    f_high=f_high,\n",
    "    noise_threshold=noise_threshold,\n",
    "    vectorized=vectorized,\n",
    "    job_kwargs=job_kwargs,\n",
    ")\n",
    "\n",
    "time_stop = time.time()\n",
    "time_taken = time_stop - time_start\n",
    "print(f\"Time elapsed: {time_taken} seconds\")\n",
    "\n",
    "time_multiprocessing = time_taken\n",
    "\n",
    "\n",
    "job_kwargs = dict(n_jobs=1, progress_bar=True, verbose=True, chunk_duration=1.0)\n",
    "time_start = time.time()\n",
    "\n",
    "spike_times_per_channel = di_carlo_pipeline(\n",
    "    recording=recording_to_use,\n",
    "    f_notch=f_notch,\n",
    "    bandwidth=bandwidth,\n",
    "    f_low=f_low,\n",
    "    f_high=f_high,\n",
    "    noise_threshold=noise_threshold,\n",
    "    vectorized=vectorized,\n",
    "    job_kwargs=job_kwargs,\n",
    ")\n",
    "\n",
    "time_stop = time.time()\n",
    "time_taken = time_stop - time_start\n",
    "print(f\"Time elapsed: {time_taken} seconds\")\n",
    "\n",
    "time_single_core = time_taken\n",
    "\n",
    "speedup = time_single_core/time_multiprocessing\n",
    "\n",
    "print(f\"Speedup: {speedup:.2f} (times faster)\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speedup = (time_non_vectorized * recording_to_use.get_duration() * 0.10 )/time_multiprocessing\n",
    "\n",
    "print(f\"Speedup with respect to non-vectorized version: {speedup:.2f} (times faster)\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full pipeline spikeinterface vs DiCarlo form Intan and NWB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load NWB Recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "folder_path = Path.home() / \"conversion_nwb\" \n",
    "# folder_path = folder_path / \"nwb_stub\"\n",
    "assert folder_path.is_dir()\n",
    "\n",
    "file_path = folder_path / \"pico_20230214_140610.nwb\"\n",
    "assert file_path.is_file()\n",
    "\n",
    "from spikeinterface.extractors import NwbRecordingExtractor\n",
    "\n",
    "\n",
    "recording = NwbRecordingExtractor(file_path=file_path)\n",
    "\n",
    "\n",
    "recording_to_use = recording\n",
    "vectorized = True\n",
    "\n",
    "job_kwargs = dict(n_jobs=-1, progress_bar=True, verbose=True, chunk_duration=1.0)\n",
    "\n",
    "time_start = time.time()\n",
    "\n",
    "spike_times_per_channel = di_carlo_pipeline(\n",
    "    recording=recording_to_use,\n",
    "    f_notch=f_notch,\n",
    "    bandwidth=bandwidth,\n",
    "    f_low=f_low,\n",
    "    f_high=f_high,\n",
    "    noise_threshold=noise_threshold,\n",
    "    vectorized=vectorized,\n",
    "    job_kwargs=job_kwargs,\n",
    ")\n",
    "\n",
    "time_stop = time.time()\n",
    "time_taken = time_stop - time_start\n",
    "print(f\"Time elapsed: {time_taken} seconds\")\n",
    "\n",
    "time_nwb = time_taken\n",
    "\n",
    "speedup = time_multiprocessing/time_nwb\n",
    "print(f\"Speedup: {speedup:.2f} (times faster)\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuroconv_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
