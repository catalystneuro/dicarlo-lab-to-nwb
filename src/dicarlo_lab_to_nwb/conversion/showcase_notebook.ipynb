{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amplifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# This has to be modified for experiment_path\n",
    "experiment_path = Path(\"/media/heberto/One Touch/DiCarlo-CN-data-share/exp_domain-transfer-2023/exp_domain-transfer-2023.sub_pico/raw_files/intanraw\")\n",
    "assert experiment_path.is_dir()\n",
    "session_folder =  experiment_path / \"pico_domain-transfer-2023_230215_161322\"\n",
    "#session_folder = experiment_path / \"pico_domain-transfer-2023_230214_140610\"  # This file has a timestamp problem\n",
    "assert session_folder.is_dir()\n",
    "\n",
    "file_path = session_folder / \"info.rhd\"\n",
    "assert file_path.is_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spikeinterface.extractors import IntanRecordingExtractor\n",
    "\n",
    "\n",
    "recording = IntanRecordingExtractor(file_path=file_path, stream_name=\"RHD2000 amplifier channel\", all_annotations=True)\n",
    "recording "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auxiliary input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_auxiliary_input = IntanRecordingExtractor(\n",
    "    file_path=file_path,\n",
    "    stream_name=\"RHD2000 auxiliary input channel\",\n",
    "    all_annotations=True,\n",
    ")\n",
    "\n",
    "recording_auxiliary_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADC input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_adc_input = IntanRecordingExtractor(\n",
    "    file_path=file_path,\n",
    "    stream_name=\"USB board ADC input channel\",\n",
    "    all_annotations=True,\n",
    ")\n",
    "\n",
    "recording_adc_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Digital channel \n",
    "Requires merging this [PR](https://github.com/NeuralEnsemble/python-neo/pull/1476) on neo library\n",
    "at the moment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_digital = IntanRecordingExtractor(\n",
    "    file_path=file_path,\n",
    "    stream_name=\"USB board digital input channel\",\n",
    "    all_annotations=True,\n",
    ")\n",
    "\n",
    "recording_digital"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artificial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spikeinterface.widgets as sw\n",
    "\n",
    "from spikeinterface.core.generate import generate_ground_truth_recording\n",
    "\n",
    "\n",
    "recording, sorting = generate_ground_truth_recording(num_channels=4, num_units=1, durations=[1], seed=0)\n",
    "\n",
    "\n",
    "w_ts = sw.plot_traces(recording, time_range=(0, 1))\n",
    "w_rs = sw.plot_rasters(sorting, time_range=(0, 1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from spikeinterface.core.job_tools import ChunkRecordingExecutor\n",
    "from dicarlo_lab_to_nwb.conversion.pipeline import calculate_peak_in_chunks, init_method\n",
    "\n",
    "\n",
    "job_name = \"DiCarloPeakDetectionPipeline\"\n",
    "job_kwargs = dict(n_jobs=1, verbose=True, progress_bar=True, chunk_duration=1.0)\n",
    "noise_threshold = 3  # The number of standard deviations for peak detection\n",
    "init_args = (recording, noise_threshold)   \n",
    "processor = ChunkRecordingExecutor(\n",
    "    recording,\n",
    "    calculate_peak_in_chunks,\n",
    "    init_method,\n",
    "    init_args,\n",
    "    handle_returns=True,\n",
    "    job_name=job_name,\n",
    "    **job_kwargs,\n",
    ")\n",
    "\n",
    "\n",
    "values = processor.run()\n",
    "spike_times_per_channel = {}\n",
    "\n",
    "number_of_chunks = len(values)\n",
    "number_of_channels = recording.get_num_channels()\n",
    "\n",
    "for channel_index in range(number_of_channels):\n",
    "    channel_spike_times = [times[channel_index] for times in values]\n",
    "    spike_times_per_channel[channel_index] = np.concatenate(channel_spike_times)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting.get_unit_spike_train(0, return_times=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_times_per_channel[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import spikeinterface.widgets as sw\n",
    "from dicarlo_lab_to_nwb.conversion.pipeline import DiCarloBandPass, DiCarloNotch, calculate_peak_in_chunks, init_method\n",
    "from spikeinterface.extractors import IntanRecordingExtractor\n",
    "\n",
    "\n",
    "# This has to be modified for experiment_path\n",
    "experiment_path = Path(\n",
    "    \"/media/heberto/One Touch/DiCarlo-CN-data-share/exp_domain-transfer-2023/exp_domain-transfer-2023.sub_pico/raw_files/intanraw\"\n",
    ")\n",
    "assert experiment_path.is_dir()\n",
    "session_folder = experiment_path / \"pico_domain-transfer-2023_230215_161322\"\n",
    "# session_folder = experiment_path / \"pico_domain-transfer-2023_230214_140610\"  # This file has a timestamp problem\n",
    "assert session_folder.is_dir()\n",
    "\n",
    "file_path = session_folder / \"info.rhd\"\n",
    "assert file_path.is_file()\n",
    "\n",
    "\n",
    "recording = IntanRecordingExtractor(\n",
    "    file_path=file_path,\n",
    "    stream_name=\"RHD2000 amplifier channel\",\n",
    "    all_annotations=True,\n",
    ")\n",
    "\n",
    "recording\n",
    "w_ts = sw.plot_traces(recording, time_range=(0, 1), return_scaled=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_notch = 50  # Hz\n",
    "bandwidth = 10\n",
    "f_low = 300.0\n",
    "f_high = 6000.0\n",
    "\n",
    "notched_recording = DiCarloNotch(recording, f_notch=f_notch, bandwidth=bandwidth)\n",
    "preprocessed_recording = DiCarloBandPass(notched_recording, f_low=f_low, f_high=f_high)\n",
    "\n",
    "# For this instance each array 96 channels, 400 micrometes apart\n",
    "w_ts = sw.plot_traces(preprocessed_recording, time_range=(0, 1), return_scaled=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run half a minute of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spikeinterface.core.job_tools import ChunkRecordingExecutor\n",
    "import numpy as np\n",
    "\n",
    "samples_in_a_minute = recording.get_sampling_frequency() * 30.0\n",
    "recording_first_minute = preprocessed_recording.frame_slice(start_frame=0, end_frame=samples_in_a_minute)\n",
    "\n",
    "job_name = \"DiCarloPeakDetectionPipeline\"\n",
    "job_kwargs = dict(n_jobs=1, verbose=True, progress_bar=True, chunk_duration=5.0)\n",
    "noise_threshold = 3  # The number of standard deviations for peak detection\n",
    "\n",
    "\n",
    "init_args = (recording_first_minute, noise_threshold)   \n",
    "processor = ChunkRecordingExecutor(\n",
    "    recording_first_minute,\n",
    "    calculate_peak_in_chunks,\n",
    "    init_method,\n",
    "    init_args,\n",
    "    handle_returns=True,\n",
    "    job_name=job_name,\n",
    "    **job_kwargs,\n",
    ")\n",
    "\n",
    "\n",
    "values = processor.run()\n",
    "spike_times_per_channel = {}\n",
    "\n",
    "number_of_chunks = len(values)\n",
    "number_of_channels = recording.get_num_channels()\n",
    "\n",
    "for channel_index in range(number_of_channels):\n",
    "    channel_spike_times = [times[channel_index] for times in values]\n",
    "    spike_times_per_channel[channel_index] = np.concatenate(channel_spike_times)\n",
    "        \n",
    "spike_times_per_channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_times_per_channel[0] * 1000.0 # ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_times_per_channel[0].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuroconv_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
